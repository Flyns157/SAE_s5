# -*- coding: utf-8 -*-
"""Image2Image

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1enmrTcprYyml3sAfN5DdmXWNuYh0SMxI
"""

"""
!nvidia-smi

!pip install -Uq diffusers ftfy accelerate
!pip install -Uq transformers
!pip install -Uq controlnet-aux
"""

import torch
import requests
from PIL import Image
from io import BytesIO
from matplotlib import pyplot as plt

from diffusers import (
    StableDiffusionPipeline,
    StableDiffusionImg2ImgPipeline,
    StableDiffusionInpaintPipeline,
    StableDiffusionDepth2ImgPipeline
    )

def download_image(url):
    response = requests.get(url)
    return Image.open(BytesIO(response.content)).convert("RGB")


def image_grid(imgs, rows, cols):
    assert len(imgs) == rows*cols

    w, h = imgs[0].size
    grid = Image.new('RGB', size=(cols*w, rows*h))
    grid_w, grid_h = grid.size

    for i, img in enumerate(imgs):
        grid.paste(img, box=(i%cols*w, i//cols*h))
    return grid

device = (
    "mps"
    if torch.backends.mps.is_available()
    else "cuda"
    if torch.cuda.is_available()
    else "cpu"
)
device

from diffusers import StableDiffusionPipeline
txt2image_pipe = StableDiffusionPipeline.from_pretrained("CompVis/stable-diffusion-v1-4", orch_dtype=torch.float16, variant="fp16", use_safetensors=True).to(device)

model_id = "stabilityai/stable-diffusion-2-1-base"
img2img_pipe = StableDiffusionImg2ImgPipeline.from_pretrained(model_id, variant="fp16", use_safetensors=True).to(device)

# Put the path of the init_image
init_image_path = "selfhost_stablediffusion_api/utils/init_image.png"
init_image = Image.open(init_image_path)

seed = 123456

# Change cpu by cuda to use nvidia gpu (more faster)
generator = torch.Generator("cpu").manual_seed(seed)

# img2img
result_image = img2img_pipe(
    prompt="An avatar of a man. Add a sword in his hand",
    image=init_image, 
    generator=generator,
    strength=1, # Between 0 and 1 (1 for maximum changes)
).images[0]

# Save the output image
output_image_path = "selfhost_stablediffusion_api/utils/output_image.png"
result_image.save(output_image_path)

# Display init and output image
fig, axs = plt.subplots(1, 2, figsize=(12, 5))
axs[0].imshow(init_image); axs[0].set_title('Input Image')
axs[1].imshow(result_image); axs[1].set_title('Result Image')
plt.show()